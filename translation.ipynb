{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abstract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We present a new dataset with the goal of advancing the state-of-the-art in object recognition by placing the question of object recognition in the context of the broader question of scene understanding. This is achieved by gathering images of complex everyday scenes containing common objects in their natural context. Objects are labeled using per-instance segmentations to aid in precise object localization. Our dataset contains photos of 91 objects types that would be easily recognizable by a 4 year old. With a total of 2.5 million labeled instances in 328k images, the creation of our dataset drew upon extensive crowd worker involvement via novel user interfaces for category detection, instance spotting and instance segmentation. We present a detailed statistical analysis of the dataset in comparison to PASCAL, ImageNet, and SUN. Finally, we provide baseline performance analysis for bounding box and segmentation detection results using a Deformable Parts Model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "摘要-要点梳理：\n",
    "+ COCO数据集是用来做 **object recognition（物体识别）**的\n",
    "+ 把 物体识别 这个研究问题，放在 具体场景中 进行识别（也就是通过寻求场景和物品的联系，来识别物体）\n",
    "+ 收集了包含自然环境中常见物体的复杂日常场景图像\n",
    "+ 使用每个**实例分割(instance segmentation)**来标记对象，以帮助精确地定位对象\n",
    "+ 数据集包含 **91种对象类型** 的照片\n",
    "+ 在328k张图像中，总共有250万个标记实例\n",
    "+ COCO提供了用户界面，进行**类别检测(category detection)、实例定位(instance spotting)和实例分割(instance segmentation)**【COCO网站+COCO API】\n",
    "+ 这篇paper还做了：\n",
    "    + 将COCO数据集与PASCAL、ImageNet和SUN进行详细的统计分析对比\n",
    "    + 使用DPM模型对边界盒和分割检测结果进行了 基线(baseline)性能分析。\n",
    "+ 补充资料：\n",
    "    + DPM是一个非常成功的目标检测算法，[DPM(Deformable Parts Model)--原理(一)](https://blog.csdn.net/ttransposition/article/details/12966521)\n",
    "    + baseline 的目的是比较提出算法的性能或者用以比较彰显提出算法的优势，[baseline和benchmark有什么区别](https://www.zhihu.com/question/22529709?sort=created)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the primary goals of computer vision is the understanding of visual scenes. Scene understanding involves numerous tasks including recognizing what objects are present, localizing the objects in 2D and 3D, determining the objects’ and scene’s attributes, charac- terizing relationships between objects and providing a semantic description of the scene. The current object clas- sification and detection datasets [1], [2], [3], [4] help us explore the first challenges related to scene understand- ing. For instance the ImageNet dataset [1], which con- tains an unprecedented number of images, has recently enabled breakthroughs in both object classification and detection research [5], [6], [7]. The community has also created datasets containing object attributes [8], scene attributes [9], keypoints [10], and 3D scene information [11]. This leads us to the obvious question: what datasets will best continue our advance towards our ultimate goal of scene understanding?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这一段要点：\n",
    "+ CV总目标-- understand visual scenes，具体涉及：\n",
    "    + **recognizing** what objects are present\n",
    "    + **localizing** the objects in 2D and 3D\n",
    "    + **determining** the objects’ and scene’s attributes\n",
    "    + **characterizing relationships** between objects \n",
    "    + providing a **semantic description** of the scene\n",
    "+ 然后说了 PASCAL、ImageNet和SUN 在 CV研究上的贡献\n",
    "+ This leads us to the obvious question: **what datasets will best continue our advance towards our ultimate goal of scene understanding?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}